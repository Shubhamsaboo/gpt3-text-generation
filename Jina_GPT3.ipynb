{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dLniCP0GVFJ"
      },
      "source": [
        "<img src ='https://drive.google.com/uc?id=1yJKb7rGr5l4GE6TuRPXeH1OvNG8MY9J4'> </img>\n",
        "\n",
        "<b>Generate human-like text using OpenAI GPT-3<sup><a href=\"https://en.wikipedia.org/wiki/GPT-3\">?</a></sup></b>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfzhUidXEuE2"
      },
      "source": [
        "[![GitHub Repo stars](https://img.shields.io/github/stars/Shubhamsaboo/gpt3-text-generation?style=social)](https://github.com/Shubhamsaboo/gpt3-text-generation) [![Google Colab](https://img.shields.io/badge/Slack-2.8k-blueviolet?logo=slack&amp;logoColor=white&style=flat-square)](https://slack.jina.ai) [![GitHub last commit (branch)](https://img.shields.io/github/last-commit/Shubhamsaboo/gpt3-text-generation/main)](https://colab.research.google.com/github/jina-ai/dalle-flow/blob/main/client.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P95Mm75sGpfn"
      },
      "source": [
        "Using the GPT-3 Executor is super easy and fun. The following steps are best run in Jupyter notebook or Google Colab.  \n",
        "\n",
        "The only dependency you will need are [DocArray](https://github.com/jina-ai/docarray) and [Jina](https://github.com/jina-ai/jina), as DocArray is already included in Jina you only need to install `jina`.\n",
        "\n",
        "> On Google Colab, you will be asked to restart the kernel. Go ahead and restart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9duPaU5Euy7"
      },
      "outputs": [],
      "source": [
        "!pip install jina"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAz7imBPHIqs"
      },
      "source": [
        "## Access to OpenAI API\n",
        "\n",
        "üöß You need access to the OpenAI API Key to use this Executor: If you don't have access to the API, please apply [here](https://openai.com/api/). üöß\n",
        "\n",
        "> Once you have the API KEY, you can pass it as uses_with: `{'api_key': 'value'}` along with the Executor name."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrHgLTZSHa7e"
      },
      "source": [
        "### Step 1: Define the prompt\n",
        "\n",
        "You can define the prompt/input as if you are asking an human to write something."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "foSr9CDSHJOT",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Insert your prompt here üëâ\n",
        "prompt = \"\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some prompt examples to make you understand how it works üëá\n",
        "\n",
        "*   **Write a poem** üëâ \"Write a shot poem on unstructured data in the style of shakespear:\"\n",
        "*   **Generate Ad Copy** üëâ \"Write a tagline for an ice cream shop:\"\n",
        "\n",
        "Now wear your creative üé© on and take your creativity to the next level! ü™ú\n",
        "\n"
      ],
      "metadata": {
        "id": "LiayHSwxW-se"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_FosYWkHnL9"
      },
      "source": [
        "Do you need some hints and suggestions on the prompt? Check out the following guides for details on Prompt Design and Engineering:\n",
        "\n",
        " - [GPT-3 Prompts Wiki](http://gptprompts.wikidot.com/)\n",
        " - [GPT-3 Prompt Hunt](https://www.buildgpt3.com/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m313_kjmIra6"
      },
      "source": [
        "### Step 2: Intialize DocumentArray\n",
        "\n",
        "You can use the inbuilt data type `DocumentArray` from jina to create a text docoument from the above prompt which we can pass to the jina `Flow`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PnK05LiuJMVl"
      },
      "outputs": [],
      "source": [
        "# Import Document and DocumentArray from the Jina library\n",
        "from docarray import Document, DocumentArray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KMK_ptHuHoqY"
      },
      "outputs": [],
      "source": [
        "da = DocumentArray([Document(text=prompt) for _ in range(1)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T571qCHgJaSp"
      },
      "source": [
        "### Step 3: Create a Flow\n",
        "\n",
        "Now you can create a jina `Flow` with `GPT3TextGeneration` Executor using the [Executor Sandbox](https://docs.jina.ai/how-to/sandbox/) to process everything in the cloud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zgo9-07tKEc1"
      },
      "outputs": [],
      "source": [
        "from jina import Flow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Input API Parameters\n",
        "api_key = \"\" #@param {type:\"string\"}\n",
        "max_tokens = 100 #@param {type:\"slider\", min:0, max:200, step:1}\n",
        "temperature = 0.35 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "print(\"API Key: \" + api_key)\n",
        "print(\"Maximum Tokens: \" + str(max_tokens))\n",
        "print(\"Temperature: \" + str(temperature))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "cVx0EIjQUvP5",
        "outputId": "88b2ccee-ece5-480d-defa-017f1bf67c83"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key: asdfasdf\n",
            "Maximum Tokens: 45\n",
            "Temperature0.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding API Parameters üëá\n",
        "\n",
        "*   **Maximum Tokens:** Maximum token sets a limit on how much text the API includes in its completion. Because OpenAI charges by the length of text generated per API call, response length is a crucial parameter for anyone on a budget.  \n",
        "\n",
        "*   **Temperature:** The temperature controls the randomness of the response, represented as a range from 0 to 1. A lower value of temperature means the API will respond with the first thing that the model sees; a higher value means the model evaluates possible responses that could fit into the context before spitting out the result.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2d_vatVshBvf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8xBjATboJJYp"
      },
      "outputs": [],
      "source": [
        "flow = Flow().add(uses='jinahub+sandbox://Gpt3TextGeneration', uses_with=({'api_key': api_key, 'max_tokens': max_tokens, 'temperature': temperature}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFO2yPXxKf6q"
      },
      "source": [
        "### Step 4: Generate the Results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232,
          "referenced_widgets": [
            "53c298ce3cec49d28e6421cc511f30a8",
            "6ca3abd3b7a540079c18cf86966c1bab"
          ]
        },
        "id": "jaWq2U08KaqE",
        "outputId": "208bc63e-b40e-459d-df1c-89207ee11700"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2;36m[08:37:52]\u001b[0m\u001b[2;36m \u001b[0müéâ A sandbox already exists, reusing it.                              \u001b]8;id=777111;file:///usr/local/lib/python3.7/dist-packages/jina/hubble/hubio.py\u001b\\\u001b[2mhubio.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=274264;file:///usr/local/lib/python3.7/dist-packages/jina/hubble/hubio.py#667\u001b\\\u001b[2m667\u001b[0m\u001b]8;;\u001b\\\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[08:37:52] </span>üéâ A sandbox already exists, reusing it.                              <a href=\"file:///usr/local/lib/python3.7/dist-packages/jina/hubble/hubio.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">hubio.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.7/dist-packages/jina/hubble/hubio.py#667\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">667</span></a>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53c298ce3cec49d28e6421cc511f30a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              ""
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "Unstructured data is like a\n",
            "wildflower in a field\n",
            "\n",
            "It's pretty and free,\n",
            "\n",
            "But it can be hard to control\n",
            "\n",
            "And it can be tough to find\n",
            "\n",
            "When you're looking for something specific\n"
          ]
        }
      ],
      "source": [
        "with flow:\n",
        "    r = flow.post(on='/complete', inputs=da)        \n",
        "    for doc in r:\n",
        "        print(\"Output:\" + \"\\n\" + doc.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's all you need to bring your imagination into reality ‚ú®\n",
        "\n",
        "[Jina](https://docs.jina.ai/)/[DocArray](https://docarray.jina.ai/) combined with GPT-3 is super productive and easy for developers, ML enthusiasts, entrepreneurs, artists to build generative cross-modal/multi-modal applciations in no time! "
      ],
      "metadata": {
        "id": "nRih8FSfjido"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Jina_GPT3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "53c298ce3cec49d28e6421cc511f30a8": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_6ca3abd3b7a540079c18cf86966c1bab",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "   Waiting \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/1\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Waiting <span style=\"color: #729c1f; text-decoration-color: #729c1f\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> <span style=\"color: #008000; text-decoration-color: #008000\">1/1</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "6ca3abd3b7a540079c18cf86966c1bab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}